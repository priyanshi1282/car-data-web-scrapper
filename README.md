# car-data-web-scrapper
This repository is the submission of the assignment under <b>Introduction to DataScience</b> module during the autmn 20025 semester at University College Dublin.
## Summary: 
The objective of this assignment is to extract a dataset from a set of web pages and use Python to prepare, analyse, and derive insights from the collected data.
The assignment should be implemented as two Jupyter Notebooks (not script files). Your notebooks should be clearly documented, using comments and Markdown cells to explain the code and interpret the results of your analysis. 
## Tasks:
Complete the following three tasks in two separate notebooks:
### 1. Data Collection
Choose one of the four data sources listed here:
http://mlg.ucd.ie/modules/python/assign1
In your first notebook, apply web scraping in Python to collect and parse all of the data from your chosen source. 
Save the collected data in an appropriate format for subsequent analysis.
### 2.  Data Preparation and Analysis
In your second notebook, load the saved dataset from Task 1 into an appropriate data structure for use as an Analytics Base Table (ABT).
Apply any data preprocessing steps that might be required to clean, filter or transform the ABT before analysis. Use Markdown cells to explain and justify each preprocessing step.
Analyse, characterise, and summarise the cleaned ABT, using visualisations where appropriate. Use Markdown cells to explain each step and interpret the results.
### 3. Discussion
At the end of your second notebook, discuss the following aspects of your assignment in Markdown cells:
Discuss any challenges faced when scraping and cleaning the data.
Summarise the key insights gained from your analysis of the data.
Suggest ideas for further work which could be performed on the data (e.g. alternative analyses, integration of other sources of data).
